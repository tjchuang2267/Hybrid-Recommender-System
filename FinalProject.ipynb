{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c85947d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import opendatasets as od\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "446d2041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \".\\movie-recommendation-system\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "download = od.download(\n",
    "    \"https://www.kaggle.com/datasets/bandikarthik/movie-recommendation-system?select=links.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84910832",
   "metadata": {},
   "outputs": [],
   "source": [
    "#links contains movie ID, imdb ID, tmdb ID\n",
    "links = pd.read_csv('movie-recommendation-system/links.csv')\n",
    "\n",
    "#movies contains movie ID, Title, Genre\n",
    "movies= pd.read_csv('movie-recommendation-system/movies.csv')\n",
    "\n",
    "#ratings contains user ID, movie ID, rating, timestamp\n",
    "ratings = pd.read_csv('movie-recommendation-system/ratings.csv')\n",
    "\n",
    "#tags contains user ID, movie ID, tag, timestamp\n",
    "tags = pd.read_csv('movie-recommendation-system/tags.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244c42f1",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbaaf3a",
   "metadata": {},
   "source": [
    "Check for sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aacbd492",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_sparsity = 1.0 - (links.count().sum() / float(links.size))\n",
    "movies_sparsity = 1.0 - (movies.count().sum() / float(movies.size))\n",
    "ratings_sparsity = 1.0 - (ratings.count().sum() / float(ratings.size))\n",
    "tags_sparsity = 1.0 - (tags.count().sum() / float(tags.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d498fcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Links Sparsity:  0.0028843155597131354\n",
      "Movies Sparsity:  0.0\n",
      "Ratings Sparsity:  0.0\n",
      "Tags Sparsity:  6.814379704067619e-06\n"
     ]
    }
   ],
   "source": [
    "print(\"Links Sparsity: \", links_sparsity)\n",
    "print(\"Movies Sparsity: \", movies_sparsity)\n",
    "print(\"Ratings Sparsity: \", ratings_sparsity)\n",
    "print(\"Tags Sparsity: \", tags_sparsity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01615e4",
   "metadata": {},
   "source": [
    "Replacing Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9274149f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmdbId is numeric so we can fill it with 0\n",
    "links = links.fillna(0)\n",
    "\n",
    "#tag is categorical data, so we will drop the rows with null vals\n",
    "tags = tags.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c81796",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4ed5cf",
   "metadata": {},
   "source": [
    "Create Dataset for Content-Based System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53272c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to combine tags and genres for our TF-IDF \n",
    "#Merging tags and movies datasets\n",
    "CB_df = movies.merge(tags, how = 'left', on = 'movieId')\n",
    "\n",
    "#Replace NaNs with genre\n",
    "CB_df['tag'] = CB_df['tag'].fillna(\"\")\n",
    "\n",
    "#Grouping by Title & concatenate tags\n",
    "agg_functions = {'movieId': 'first', 'tag': ' '.join, 'genres': 'first'}\n",
    "combined_tags = CB_df.groupby('title', as_index = False).aggregate(agg_functions)\n",
    "\n",
    "#Combine tag and genres\n",
    "combined_tags[\"newtag\"] = combined_tags[['tag', 'genres']].agg(' '.join, axis = 1)\n",
    "\n",
    "#Drop unnecessary columns\n",
    "combined_tags = combined_tags.drop('tag', axis = 1)\n",
    "combined_tags = combined_tags.drop('genres', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01557eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get top 10 users with most reviews\n",
    "count = ratings.groupby('userId').size()\n",
    "top_10 = count.sort_values(ascending = False).head(10)\n",
    "top_10 = pd.DataFrame(top_10)\n",
    "\n",
    "#Merge top_10 with ratings to get the ratings for the top 10 users\n",
    "sampled_df = top_10.merge(ratings, how = 'left', right_on = 'userId', left_on = top_10.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fe91420",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We only need the movies that have ratings, so we merge ratings with combined_tags\n",
    "merged = sampled_df.merge(movies, how = 'left', left_on = 'movieId', right_on = 'movieId')\n",
    "\n",
    "merged = merged.merge(combined_tags, how = 'left', left_on = 'title', right_on = 'title')\n",
    "\n",
    "#Dropping unnecessary columns\n",
    "merged = merged.drop('timestamp', axis = 1)\n",
    "merged = merged.drop('movieId_y', axis = 1)\n",
    "\n",
    "agg_functions = {'title': 'first', 'newtag': 'first'}\n",
    "CB_merged = merged.groupby('movieId_x', as_index = False).aggregate(agg_functions)\n",
    "\n",
    "#We want to sample CB_merged to reduce rows\n",
    "sampled_data = CB_merged[:2500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1ce03d",
   "metadata": {},
   "source": [
    "# Content-Based Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fff8bf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4d0f8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Tim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Tim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ecfb66",
   "metadata": {},
   "source": [
    "### CB Pt 1) Preprocessing: Stop word removal + stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8228190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w.lower() in stop_words]\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_words = [stemmer.stem(w) for w in words]\n",
    "    preprocessed_text = ' '.join(stemmed_words)\n",
    "    \n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "567f116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_tags = []\n",
    "for i in sampled_data['newtag']:\n",
    "    preprocessed_text = preprocess_text(i)\n",
    "    preprocessed_tags.append(preprocessed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7734b3d5",
   "metadata": {},
   "source": [
    "### CB Pt 2) TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "953661a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(preprocessed_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be72918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "tfidf_vectors = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd6cdd7",
   "metadata": {},
   "source": [
    "### CB Pt 3) Recommender Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b7b3fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate cosine similarity matrix\n",
    "cosine_sim = cosine_similarity(tfidf_vectors, tfidf_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15001836",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct Ratings matrix\n",
    "ratings_matrix = merged.pivot_table(index = 'userId', columns = 'movieId_x', values = 'rating', fill_value = 0)\n",
    "\n",
    "#Limit Ratings matrix to first 2500 movies\n",
    "ratings_matrix = ratings_matrix.iloc[:, :2500]\n",
    "ratings_matrix = np.array(ratings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34ab6e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split ratings matrix into train/test sets\n",
    "train_matrix, test_matrix = train_test_split(ratings_matrix, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0f1b793",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the predicted ratings based on cosine similarity matrix\n",
    "predicted_ratings = np.dot(cosine_sim, train_matrix.T) / np.sum(cosine_sim, axis = 1, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72b7b58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten predicted ratings and actual ratings\n",
    "predicted_ratings_flat = predicted_ratings.flatten()\n",
    "test_ratings_flat = test_matrix.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab0680ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out zero ratings\n",
    "nonzero_indices = np.nonzero(test_ratings_flat)\n",
    "predicted_ratings_nonzero = predicted_ratings_flat[nonzero_indices]\n",
    "test_ratings_nonzero = test_ratings_flat[nonzero_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ba229ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(test_ratings_nonzero, predicted_ratings_nonzero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "000cbc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.988123742312418"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9355326",
   "metadata": {},
   "source": [
    "# Proposed Hybrid System "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3f65d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bfd093",
   "metadata": {},
   "source": [
    "### Hybrid Pt 1) Calculate Similarity Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6badb2c",
   "metadata": {},
   "source": [
    "Item-Rating similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5b9d7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Item-Rating similarity using cosine similarity\n",
    "\n",
    "#We want to subtract the user means from all non-zero values\n",
    "matrix = ratings_matrix.copy()\n",
    "RI_sim = cosine_similarity(matrix.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b8559c",
   "metadata": {},
   "source": [
    "Item-Demographic similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f324583",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Item-Demographic similarity using vector similarity\n",
    "\n",
    "demo_matrix = merged.groupby('movieId_x')['genres'].first().reset_index()\n",
    "demo_matrix = demo_matrix.head(2500)\n",
    "\n",
    "preprocessed_tags = []\n",
    "for i in demo_matrix['genres']:\n",
    "    preprocessed_text = preprocess_text(i)\n",
    "    preprocessed_tags.append(preprocessed_text)\n",
    "    \n",
    "X = np.array(preprocessed_tags)\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_vectors = vectorizer.fit_transform(X)\n",
    "\n",
    "DI_sim = cosine_similarity(tfidf_vectors, tfidf_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee88c1f",
   "metadata": {},
   "source": [
    "Item-Feature similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79ce603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Item-Feature similarity using vector similarity\n",
    "\n",
    "feature_matrix = sampled_df.movieId.unique()\n",
    "feature_matrix = pd.DataFrame(feature_matrix)\n",
    "feature_matrix = feature_matrix.merge(tags, how = 'left', left_on = feature_matrix[0], right_on = 'movieId')\n",
    "feature_matrix.dropna(subset = ['movieId'], inplace = True)\n",
    "feature_matrix['tag'].fillna(\" \", inplace = True)\n",
    "feature_matrix = feature_matrix.groupby('movieId')['tag'].agg(' '.join).reset_index()\n",
    "feature_matrix = feature_matrix.head(2500)\n",
    "\n",
    "preprocessed_tags = []\n",
    "for i in feature_matrix['tag']:\n",
    "    preprocessed_text = preprocess_text(i)\n",
    "    preprocessed_tags.append(preprocessed_text)\n",
    "    \n",
    "X = np.array(preprocessed_tags)\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_vectors = vectorizer.fit_transform(X)\n",
    "\n",
    "FI_sim = cosine_similarity(tfidf_vectors, tfidf_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621b865d",
   "metadata": {},
   "source": [
    "Candidate Itemset similarity matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "edf464f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to find candidate neighbors based on similarity to target item\n",
    "def get_candidates(feature_similarities, target, k):\n",
    "    #Get similarity values for target item\n",
    "    target_item_similarities = feature_similarities[target]\n",
    "    \n",
    "    #Sort values in descending order & exclude target\n",
    "    sorted_sim = np.argsort(target_item_similarities)[::-1]\n",
    "    sorted_sim = sorted_sim[sorted_sim != target]\n",
    "    \n",
    "    top_k = sorted_sim[:k]\n",
    "    \n",
    "    return top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e013696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to find RD_sim, DD_sim, FD_sim\n",
    "#Turns item similarity matrices into sparse matrices that only contain the candidate movies\n",
    "def get_candidate_sims(sim_matr, candidates):\n",
    "    rows = []\n",
    "    cols = []\n",
    "    data = []\n",
    "\n",
    "    for i in candidates:\n",
    "        for j in candidates:\n",
    "            rows.append(i)\n",
    "            cols.append(j)\n",
    "            data.append(sim_matr[i, j])\n",
    "\n",
    "    output = sparse.coo_matrix((data, (rows, cols)), shape = sim_matr.shape)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a972391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top20 = get_candidates(FI_sim, 1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f6b5233",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate RD_sim, FD_sim, DD_sim\n",
    "RD_sim = get_candidate_sims(RI_sim, top20)\n",
    "RD_sim = RD_sim.toarray()\n",
    "\n",
    "FD_sim = get_candidate_sims(FI_sim, top20)\n",
    "FD_sim = FD_sim.toarray()\n",
    "\n",
    "DD_sim = get_candidate_sims(DI_sim, top20)\n",
    "DD_sim = DD_sim.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ab4fbe",
   "metadata": {},
   "source": [
    "### Hybrid Pt 2)  Calculating BoostedSim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b95daaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split ratings matrix into train/test sets\n",
    "train_matrix, test_matrix = train_test_split(ratings_matrix, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65c398a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prints a list of the similarity matrices associated with each matrix in linear_combination\n",
    "def print_index_better():\n",
    "    matrices = ['FI_sim', 'DI_sim', 'RI_sim', 'FD_sim', 'DD_sim', 'RD_sim']\n",
    "\n",
    "    combinations = []\n",
    "    for r in range(1, len(matrices) + 1):\n",
    "        combinations.extend(list(itertools.combinations(matrices, r)))\n",
    "\n",
    "    for i, combination in enumerate(combinations, start=1):\n",
    "        print(\"Index:\", i)\n",
    "        print(\"Matrices:\", combination)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c343371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate MAE for each matrix in linear_combinations\n",
    "def fmax(matrices, training_data):\n",
    "    mae_list = []\n",
    "\n",
    "    for i in matrices:\n",
    "        predicted_ratings = np.dot(i, training_data.T)\n",
    "        \n",
    "        absolute_diff = np.abs(predicted_ratings - training_data.T)\n",
    "        \n",
    "        mae = np.mean(absolute_diff)\n",
    "        mae_list.append(mae)\n",
    "    \n",
    "    lowest_mae = mae_list.index(min(mae_list)) + 1\n",
    "   \n",
    "    return lowest_mae, mae_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0aa87c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_matrices(matrices):\n",
    "    combined_matrix = np.zeros_like(matrices[0])\n",
    "    for matrix in matrices:\n",
    "        combined_matrix += matrix\n",
    "    return combined_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80474577",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find optimal weights for Boosted_sim\n",
    "def find_optimal_weights(α, β, FD_sim, DD_sim):\n",
    "    matrices = []\n",
    "    \n",
    "    for i in range(len(α)):\n",
    "        matrices.append(α[i]*FD_sim + β[i]*DD_sim)\n",
    "    \n",
    "    fmax_index, mae_list = fmax(matrices, train_matrix)\n",
    "    \n",
    "    #Find the index of the smallest MAE in mae_list\n",
    "    least_index = mae_list.index(min(mae_list))\n",
    "    least_α = α[least_index]\n",
    "    least_β = β[least_index]\n",
    "    \n",
    "    return least_α, least_β"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b00e780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform linear combination on matrices combinations\n",
    "similarity_matrices = [FI_sim, DI_sim, RI_sim, FD_sim, DD_sim, RD_sim]\n",
    "\n",
    "all_combinations = []\n",
    "linear_combinations = []\n",
    "\n",
    "for i in range(1, len(similarity_matrices) + 1):\n",
    "    combinations = itertools.combinations(similarity_matrices, i)\n",
    "    all_combinations.extend(combinations)\n",
    "    \n",
    "for combination in all_combinations:\n",
    "    linear_combination = combine_matrices(combination)\n",
    "    linear_combinations.append(linear_combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1d4fc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmax_index, mae_list = fmax(linear_combinations, train_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2faf34e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 1\n",
      "Matrices: ('FI_sim',)\n",
      "\n",
      "Index: 2\n",
      "Matrices: ('DI_sim',)\n",
      "\n",
      "Index: 3\n",
      "Matrices: ('RI_sim',)\n",
      "\n",
      "Index: 4\n",
      "Matrices: ('FD_sim',)\n",
      "\n",
      "Index: 5\n",
      "Matrices: ('DD_sim',)\n",
      "\n",
      "Index: 6\n",
      "Matrices: ('RD_sim',)\n",
      "\n",
      "Index: 7\n",
      "Matrices: ('FI_sim', 'DI_sim')\n",
      "\n",
      "Index: 8\n",
      "Matrices: ('FI_sim', 'RI_sim')\n",
      "\n",
      "Index: 9\n",
      "Matrices: ('FI_sim', 'FD_sim')\n",
      "\n",
      "Index: 10\n",
      "Matrices: ('FI_sim', 'DD_sim')\n",
      "\n",
      "Index: 11\n",
      "Matrices: ('FI_sim', 'RD_sim')\n",
      "\n",
      "Index: 12\n",
      "Matrices: ('DI_sim', 'RI_sim')\n",
      "\n",
      "Index: 13\n",
      "Matrices: ('DI_sim', 'FD_sim')\n",
      "\n",
      "Index: 14\n",
      "Matrices: ('DI_sim', 'DD_sim')\n",
      "\n",
      "Index: 15\n",
      "Matrices: ('DI_sim', 'RD_sim')\n",
      "\n",
      "Index: 16\n",
      "Matrices: ('RI_sim', 'FD_sim')\n",
      "\n",
      "Index: 17\n",
      "Matrices: ('RI_sim', 'DD_sim')\n",
      "\n",
      "Index: 18\n",
      "Matrices: ('RI_sim', 'RD_sim')\n",
      "\n",
      "Index: 19\n",
      "Matrices: ('FD_sim', 'DD_sim')\n",
      "\n",
      "Index: 20\n",
      "Matrices: ('FD_sim', 'RD_sim')\n",
      "\n",
      "Index: 21\n",
      "Matrices: ('DD_sim', 'RD_sim')\n",
      "\n",
      "Index: 22\n",
      "Matrices: ('FI_sim', 'DI_sim', 'RI_sim')\n",
      "\n",
      "Index: 23\n",
      "Matrices: ('FI_sim', 'DI_sim', 'FD_sim')\n",
      "\n",
      "Index: 24\n",
      "Matrices: ('FI_sim', 'DI_sim', 'DD_sim')\n",
      "\n",
      "Index: 25\n",
      "Matrices: ('FI_sim', 'DI_sim', 'RD_sim')\n",
      "\n",
      "Index: 26\n",
      "Matrices: ('FI_sim', 'RI_sim', 'FD_sim')\n",
      "\n",
      "Index: 27\n",
      "Matrices: ('FI_sim', 'RI_sim', 'DD_sim')\n",
      "\n",
      "Index: 28\n",
      "Matrices: ('FI_sim', 'RI_sim', 'RD_sim')\n",
      "\n",
      "Index: 29\n",
      "Matrices: ('FI_sim', 'FD_sim', 'DD_sim')\n",
      "\n",
      "Index: 30\n",
      "Matrices: ('FI_sim', 'FD_sim', 'RD_sim')\n",
      "\n",
      "Index: 31\n",
      "Matrices: ('FI_sim', 'DD_sim', 'RD_sim')\n",
      "\n",
      "Index: 32\n",
      "Matrices: ('DI_sim', 'RI_sim', 'FD_sim')\n",
      "\n",
      "Index: 33\n",
      "Matrices: ('DI_sim', 'RI_sim', 'DD_sim')\n",
      "\n",
      "Index: 34\n",
      "Matrices: ('DI_sim', 'RI_sim', 'RD_sim')\n",
      "\n",
      "Index: 35\n",
      "Matrices: ('DI_sim', 'FD_sim', 'DD_sim')\n",
      "\n",
      "Index: 36\n",
      "Matrices: ('DI_sim', 'FD_sim', 'RD_sim')\n",
      "\n",
      "Index: 37\n",
      "Matrices: ('DI_sim', 'DD_sim', 'RD_sim')\n",
      "\n",
      "Index: 38\n",
      "Matrices: ('RI_sim', 'FD_sim', 'DD_sim')\n",
      "\n",
      "Index: 39\n",
      "Matrices: ('RI_sim', 'FD_sim', 'RD_sim')\n",
      "\n",
      "Index: 40\n",
      "Matrices: ('RI_sim', 'DD_sim', 'RD_sim')\n",
      "\n",
      "Index: 41\n",
      "Matrices: ('FD_sim', 'DD_sim', 'RD_sim')\n",
      "\n",
      "Index: 42\n",
      "Matrices: ('FI_sim', 'DI_sim', 'RI_sim', 'FD_sim')\n",
      "\n",
      "Index: 43\n",
      "Matrices: ('FI_sim', 'DI_sim', 'RI_sim', 'DD_sim')\n",
      "\n",
      "Index: 44\n",
      "Matrices: ('FI_sim', 'DI_sim', 'RI_sim', 'RD_sim')\n",
      "\n",
      "Index: 45\n",
      "Matrices: ('FI_sim', 'DI_sim', 'FD_sim', 'DD_sim')\n",
      "\n",
      "Index: 46\n",
      "Matrices: ('FI_sim', 'DI_sim', 'FD_sim', 'RD_sim')\n",
      "\n",
      "Index: 47\n",
      "Matrices: ('FI_sim', 'DI_sim', 'DD_sim', 'RD_sim')\n",
      "\n",
      "Index: 48\n",
      "Matrices: ('FI_sim', 'RI_sim', 'FD_sim', 'DD_sim')\n",
      "\n",
      "Index: 49\n",
      "Matrices: ('FI_sim', 'RI_sim', 'FD_sim', 'RD_sim')\n",
      "\n",
      "Index: 50\n",
      "Matrices: ('FI_sim', 'RI_sim', 'DD_sim', 'RD_sim')\n",
      "\n",
      "Index: 51\n",
      "Matrices: ('FI_sim', 'FD_sim', 'DD_sim', 'RD_sim')\n",
      "\n",
      "Index: 52\n",
      "Matrices: ('DI_sim', 'RI_sim', 'FD_sim', 'DD_sim')\n",
      "\n",
      "Index: 53\n",
      "Matrices: ('DI_sim', 'RI_sim', 'FD_sim', 'RD_sim')\n",
      "\n",
      "Index: 54\n",
      "Matrices: ('DI_sim', 'RI_sim', 'DD_sim', 'RD_sim')\n",
      "\n",
      "Index: 55\n",
      "Matrices: ('DI_sim', 'FD_sim', 'DD_sim', 'RD_sim')\n",
      "\n",
      "Index: 56\n",
      "Matrices: ('RI_sim', 'FD_sim', 'DD_sim', 'RD_sim')\n",
      "\n",
      "Index: 57\n",
      "Matrices: ('FI_sim', 'DI_sim', 'RI_sim', 'FD_sim', 'DD_sim')\n",
      "\n",
      "Index: 58\n",
      "Matrices: ('FI_sim', 'DI_sim', 'RI_sim', 'FD_sim', 'RD_sim')\n",
      "\n",
      "Index: 59\n",
      "Matrices: ('FI_sim', 'DI_sim', 'RI_sim', 'DD_sim', 'RD_sim')\n",
      "\n",
      "Index: 60\n",
      "Matrices: ('FI_sim', 'DI_sim', 'FD_sim', 'DD_sim', 'RD_sim')\n",
      "\n",
      "Index: 61\n",
      "Matrices: ('FI_sim', 'RI_sim', 'FD_sim', 'DD_sim', 'RD_sim')\n",
      "\n",
      "Index: 62\n",
      "Matrices: ('DI_sim', 'RI_sim', 'FD_sim', 'DD_sim', 'RD_sim')\n",
      "\n",
      "Index: 63\n",
      "Matrices: ('FI_sim', 'DI_sim', 'RI_sim', 'FD_sim', 'DD_sim', 'RD_sim')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_index_better()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d3a49517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[47.81938324842951,\n",
       " 662.5179770280289,\n",
       " 2564.7794489109,\n",
       " 1.669476575992371,\n",
       " 1.6894403249922278,\n",
       " 1.8267525103617972,\n",
       " 711.8570852764583,\n",
       " 2614.118557159329,\n",
       " 47.89003482442188,\n",
       " 47.909998573421746,\n",
       " 48.04731075879131,\n",
       " 3228.927000938929,\n",
       " 662.5886286040211,\n",
       " 662.608592353021,\n",
       " 662.7459045383906,\n",
       " 2564.8501004868926,\n",
       " 2564.870064235892,\n",
       " 2565.0073764212616,\n",
       " 1.7600919009845988,\n",
       " 1.8974040863541684,\n",
       " 1.9173678353540247,\n",
       " 3278.266109187359,\n",
       " 711.9277368524507,\n",
       " 711.9477006014505,\n",
       " 712.0850127868201,\n",
       " 2614.1892087353217,\n",
       " 2614.2091724843217,\n",
       " 2614.346484669691,\n",
       " 47.98065014941411,\n",
       " 48.117962334783684,\n",
       " 48.13792608378354,\n",
       " 3228.9976525149214,\n",
       " 3229.0176162639214,\n",
       " 3229.1549284492908,\n",
       " 662.6792439290133,\n",
       " 662.8165561143828,\n",
       " 662.8365198633827,\n",
       " 2564.9407158118843,\n",
       " 2565.078027997254,\n",
       " 2565.0979917462537,\n",
       " 1.9880194113463956,\n",
       " 3278.336760763351,\n",
       " 3278.3567245123504,\n",
       " 3278.49403669772,\n",
       " 712.0183521774429,\n",
       " 712.1556643628124,\n",
       " 712.1756281118123,\n",
       " 2614.2798240603142,\n",
       " 2614.4171362456837,\n",
       " 2614.437099994683,\n",
       " 48.20857765977591,\n",
       " 3229.0882678399134,\n",
       " 3229.225580025283,\n",
       " 3229.245543774283,\n",
       " 662.9071714393751,\n",
       " 2565.168643322246,\n",
       " 3278.427376088343,\n",
       " 3278.564688273713,\n",
       " 3278.5846520227124,\n",
       " 712.2462796878048,\n",
       " 2614.5077515706757,\n",
       " 3229.3161953502754,\n",
       " 3278.655303598705]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ea829c",
   "metadata": {},
   "source": [
    "We see that the combination of FD_sim and DD_sim has a low MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a7b2fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the combination of weights that produces lowest MAE\n",
    "α = [.1, .2, .3, .4, .5, .6, .7, .8, .9]\n",
    "β = [.9, .8, .7, .6, .5, .4, .3, .2, .1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "82b78a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_α, optimal_β = find_optimal_weights(α, β, FD_sim, DD_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "03a9d1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Boosted_sim = optimal_α*FD_sim + optimal_β*DD_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8c0ba8",
   "metadata": {},
   "source": [
    "## Hybrid Pt 3) Predict ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e40ab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(target_item, user_index ,boostedsim):\n",
    "    top10 = get_candidates(FI_sim, target_item, 10)\n",
    "    \n",
    "    #Calculate RD_sim, FD_sim, DD_sim based on target_item\n",
    "    RD_sim = get_candidate_sims(RI_sim, top10)\n",
    "    RD_sim = RD_sim.toarray()\n",
    "\n",
    "    FD_sim = get_candidate_sims(FI_sim, top10)\n",
    "    FD_sim = FD_sim.toarray()\n",
    "\n",
    "    DD_sim = get_candidate_sims(DI_sim, top10)\n",
    "    DD_sim = DD_sim.toarray()\n",
    "    \n",
    "    \n",
    "    #Generate linear combinations of every possible combination of similarity matrices\n",
    "    similarity_matrices = [FI_sim, DI_sim, RI_sim, FD_sim, DD_sim, RD_sim]\n",
    "\n",
    "    all_combinations = []\n",
    "    linear_combinations = []\n",
    "  \n",
    "    for i in range(1, len(similarity_matrices) + 1):\n",
    "        combinations = itertools.combinations(similarity_matrices, i)\n",
    "        all_combinations.extend(combinations)\n",
    "\n",
    "    for combination in all_combinations:\n",
    "        linear_combination = combine_matrices(combination)\n",
    "        linear_combinations.append(linear_combination)\n",
    "        \n",
    "        \n",
    "    #We want to predict the ratings for user in index 0\n",
    "    numerator = []\n",
    "    denominator = []\n",
    "    for i in top10:\n",
    "        numerator.append(boostedsim * ratings_matrix[user_index, i])\n",
    "        denominator.append(abs(Boosted_sim))\n",
    "    numerator = np.sum(numerator)\n",
    "    denominator = np.sum(denominator)\n",
    "    rating = numerator / denominator\n",
    "    \n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8fadc3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all the ratings for user 0\n",
    "user_predict = []\n",
    "for i in range(100):\n",
    "    user_predict.append(get_predictions(target_item = i, user_index = 0, boostedsim = Boosted_sim))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4e9bae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = ratings_matrix[0, :100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b127be04",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(user_predict, validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6512aaff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3504999999999998"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ec8cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
